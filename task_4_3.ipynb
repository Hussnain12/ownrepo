{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, Conv2DTranspose\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masks(train_images_folder, train_masks_folder):\n",
    "    mask_files = glob.glob(os.path.join(train_masks_folder, '*.tif'))\n",
    "\n",
    "    # Preprocess mask filenames\n",
    "    mask_dict = {}\n",
    "    for m_path in mask_files:\n",
    "        base_name = os.path.basename(m_path).split('.')[0].rsplit('_', 2)[0].rsplit('_occluded', 1)[0]\n",
    "        mask_dict.setdefault(base_name, []).append(m_path)\n",
    "\n",
    "    images, masks = [], []\n",
    "    for img_path in glob.glob(os.path.join(train_images_folder, '*.png')):\n",
    "        img_name = os.path.basename(img_path).split('.')[0]\n",
    "\n",
    "        if img_name in mask_dict and len(mask_dict[img_name]) == 4:\n",
    "            images.append(img_path)\n",
    "            masks.append(mask_dict[img_name])\n",
    "\n",
    "    return images, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_petri_dish_thresholding(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply adaptive thresholding\n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter contours based on area to find the Petri dish contour\n",
    "    petri_dish_contour = None\n",
    "    min_contour_area = 4000 \n",
    "\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > min_contour_area:\n",
    "            petri_dish_contour = contour\n",
    "            break\n",
    "\n",
    "    # Extract bounding box coordinates of the Petri dish\n",
    "    x, y, w, h = cv2.boundingRect(petri_dish_contour)\n",
    "\n",
    "    # Ensure the bounding box is a square\n",
    "    side_length = max(w, h)\n",
    "    x_center, y_center = x + w // 2, y + h // 2\n",
    "\n",
    "    # Crop the Petri dish from the original image\n",
    "    petri_dish = image[y:y + h, x:x + w]\n",
    "\n",
    "    # Resize the cropped Petri dish to 2770x2770\n",
    "    petri_dish = cv2.resize(petri_dish, (2770, 2770))\n",
    "\n",
    "    # Convert the cropped Petri dish to grayscale\n",
    "    petri_dish_gray = cv2.cvtColor(petri_dish, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    return petri_dish_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padder(image, patch_size):\n",
    "    h = image.shape[0]\n",
    "    w = image.shape[1]\n",
    "    height_padding = ((h // patch_size) + 1) * patch_size - h\n",
    "    width_padding = ((w // patch_size) + 1) * patch_size - w\n",
    "\n",
    "    top_padding = int(height_padding/2)\n",
    "    bottom_padding = height_padding - top_padding\n",
    "\n",
    "    left_padding = int(width_padding/2)\n",
    "    right_padding = width_padding - left_padding\n",
    "\n",
    "    padded_image = cv2.copyMakeBorder(image, top_padding, bottom_padding, left_padding, right_padding, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "\n",
    "    return padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(images, masks, patch_size):\n",
    "    patch_images, patch_masks = [], []\n",
    "\n",
    "    for img_path, mask_paths in zip(images, masks):\n",
    "        # Load image\n",
    "        image = cv2.imread(img_path)\n",
    "\n",
    "        # Check if masks exist\n",
    "        if not all(os.path.exists(mask_path) for mask_path in mask_paths):\n",
    "            continue\n",
    "\n",
    "        # Find and crop Petri dish\n",
    "        petri_dish = find_petri_dish_thresholding(image)\n",
    "\n",
    "        # Padding\n",
    "        padded_petri_dish = padder(petri_dish, patch_size)\n",
    "\n",
    "        # Patching\n",
    "        patch_size = 256\n",
    "        num_channels = 3  # Assuming RGB images\n",
    "\n",
    "        # Calculate the number of patches in each dimension\n",
    "        num_patches_h = padded_petri_dish.shape[0] // patch_size\n",
    "        num_patches_w = padded_petri_dish.shape[1] // patch_size\n",
    "\n",
    "        # Initialize an empty list for patches\n",
    "        patch_images = []\n",
    "\n",
    "        # Extract patches directly using numpy slicing\n",
    "        for i in range(num_patches_h):\n",
    "            for j in range(num_patches_w):\n",
    "                if padded_petri_dish.ndim == 3:  # Color image\n",
    "                    patch = padded_petri_dish[i * patch_size:(i + 1) * patch_size, j * patch_size:(j + 1) * patch_size, :]\n",
    "                else:  # Grayscale image\n",
    "                    patch = padded_petri_dish[i * patch_size:(i + 1) * patch_size, j * patch_size:(j + 1) * patch_size]\n",
    "                    patch = np.expand_dims(patch, axis=-1)  # Add the third dimension for compatibility with color images\n",
    "                patch_images.append(patch)\n",
    "\n",
    "        # Convert to numpy array\n",
    "        patch_images = np.array(patch_images)\n",
    "\n",
    "\n",
    "        # Append to lists\n",
    "        patch_masks.extend([cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE) for mask_path in mask_paths])\n",
    "\n",
    "    return patch_images, np.array(patch_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your dataset path\n",
    "dataset_folder = r\"C:\\Users\\User\\Desktop\\2023-24b-fai2-adsai-yuliiabobrovytska226038\\1. Computer Vision\\DataLab tasks\\Task 4\\dataset\"\n",
    "train_images_folder = os.path.join(dataset_folder, 'train_images', 'train')\n",
    "train_masks_folder = os.path.join(dataset_folder, 'train_masks', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set patch size\n",
    "patch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images and masks\n",
    "images, masks = get_masks(train_images_folder, train_masks_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "patch_images, patch_masks = preprocess_data(images, masks, patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 256, 256, 1)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 3006, 4202)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming num_classes is defined earlier in your code\n",
    "num_classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = TP / (Positives+K.epsilon())\n",
    "        return recall\n",
    "    \n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = TP / (Pred_Positives+K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "    \n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(y_true, y_pred):\n",
    "    def f(y_true, y_pred):\n",
    "        intersection = K.sum(K.abs(y_true * y_pred), axis=[1, 2])\n",
    "        total = K.sum(K.square(y_true), axis=[1, 2]) + K.sum(K.square(y_pred), axis=[1, 2])\n",
    "        union = total - intersection\n",
    "        return (intersection + K.epsilon()) / (union + K.epsilon())\n",
    "\n",
    "    return K.mean(f(y_true, y_pred), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS):\n",
    "# Build the model\n",
    "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    s = inputs\n",
    "\n",
    "    # Contraction path\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "     \n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "     \n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "     \n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "    \n",
    "    # Expansive path \n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "     \n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "     \n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "     \n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "     \n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='softmax')(c9)\n",
    "     \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', f1, iou])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the image dimensions\n",
    "IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = patch_size, patch_size, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 256, 256, 16  448         ['input_3[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 256, 256, 16  0           ['conv2d_38[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 256, 256, 16  2320        ['dropout_18[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 128, 128, 16  0          ['conv2d_39[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 128, 128, 32  4640        ['max_pooling2d_8[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 128, 128, 32  0           ['conv2d_40[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 128, 128, 32  9248        ['dropout_19[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 64, 64, 32)  0           ['conv2d_41[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 64, 64, 64)   18496       ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 64, 64, 64)   0           ['conv2d_42[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 64, 64, 64)   36928       ['dropout_20[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 32, 32, 64)  0           ['conv2d_43[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 32, 32, 128)  73856       ['max_pooling2d_10[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)           (None, 32, 32, 128)  0           ['conv2d_44[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 32, 32, 128)  147584      ['dropout_21[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 16, 16, 128)  0          ['conv2d_45[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 16, 16, 256)  295168      ['max_pooling2d_11[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 16, 16, 256)  0           ['conv2d_46[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 16, 16, 256)  590080      ['dropout_22[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_8 (Conv2DTran  (None, 32, 32, 128)  131200     ['conv2d_47[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 32, 32, 256)  0           ['conv2d_transpose_8[0][0]',     \n",
      "                                                                  'conv2d_45[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 32, 32, 128)  295040      ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 32, 32, 128)  0           ['conv2d_48[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 32, 32, 128)  147584      ['dropout_23[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_9 (Conv2DTran  (None, 64, 64, 64)  32832       ['conv2d_49[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 64, 64, 128)  0           ['conv2d_transpose_9[0][0]',     \n",
      "                                                                  'conv2d_43[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 64, 64, 64)   73792       ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 64, 64, 64)   0           ['conv2d_50[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 64, 64, 64)   36928       ['dropout_24[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_10 (Conv2DTra  (None, 128, 128, 32  8224       ['conv2d_51[0][0]']              \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 128, 128, 64  0           ['conv2d_transpose_10[0][0]',    \n",
      "                                )                                 'conv2d_41[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 128, 128, 32  18464       ['concatenate_10[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 128, 128, 32  0           ['conv2d_52[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 128, 128, 32  9248        ['dropout_25[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_11 (Conv2DTra  (None, 256, 256, 16  2064       ['conv2d_53[0][0]']              \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 256, 256, 32  0           ['conv2d_transpose_11[0][0]',    \n",
      "                                )                                 'conv2d_39[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 256, 256, 16  4624        ['concatenate_11[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)           (None, 256, 256, 16  0           ['conv2d_54[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 256, 256, 16  2320        ['dropout_26[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 256, 256, 5)  85          ['conv2d_55[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,941,173\n",
      "Trainable params: 1,941,173\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = simple_unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [121, 352]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[143], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Split the dataset into training and testing sets\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatch_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\google\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\google\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2614\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2612\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2614\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2616\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   2617\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2618\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2619\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\google\\lib\\site-packages\\sklearn\\utils\\validation.py:455\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \n\u001b[0;32m    438\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    454\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 455\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\google\\lib\\site-packages\\sklearn\\utils\\validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    407\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    412\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [121, 352]"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(patch_images, patch_masks, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up callbacks for training\n",
    "checkpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_loss', save_best_only=True, save_weights_only=True, mode='min', verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=16, callbacks=[checkpoint, early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "results = model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the test set loss, accuracy, F1 score, and IoU\n",
    "print(\"Test Loss:\", results[0])\n",
    "print(\"Test Accuracy:\", results[1])\n",
    "print(\"Test F1 Score:\", results[2])\n",
    "print(\"Test IoU:\", results[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "google",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
